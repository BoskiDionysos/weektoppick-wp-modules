name: Snapshot Watchdog (full)

on:
  push:
    branches: [ main ]
    paths:
      - 'mu-plugins/wtp-ro-exporter.php'
      - '.github/workflows/snapshot-watchdog.yml'
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch: {}

permissions:
  contents: write
  issues: write

concurrency:
  group: snapshot-watchdog
  cancel-in-progress: true

jobs:
  check:
    runs-on: ubuntu-latest
    env:
      BASE: https://weektoppick.com
      NS: wtp-ro-open/v1
      SITE_KEY: 5Depft8Y9LU0t6Sv
      OPS: ops-snapshot-watchdog
      STATE_DIR: .wtp/state
      STATE_FILE: .wtp/state/snapshot-files.json
      DELTA_HARD_LIMIT: "5"
      SAMPLE_N: "3"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Tools & dirs
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl
          mkdir -p "$OPS" "$STATE_DIR"

      - name: GET /health
        id: health
        run: |
          set -euo pipefail
          URL="${BASE}/wp-json/${NS}/health?site_key=${SITE_KEY}"
          echo "GET $URL"
          body="$(curl -sS -w '\n%{http_code}\n' "$URL" || true)"
          http="$(echo "$body" | tail -n1)"
          payload="$(echo "$body" | head -n-1)"
          printf '%s\n' "$payload" > "$OPS/health.json" || true
          echo "status=$http" >> "$GITHUB_OUTPUT"
          echo "ok_json=$(jq -e 'type==\"object\"' "$OPS/health.json" >/dev/null 2>&1 && echo yes || echo no)" >> "$GITHUB_OUTPUT"

      - name: GET /ls
        id: ls
        run: |
          set -euo pipefail
          URL="${BASE}/wp-json/${NS}/ls?site_key=${SITE_KEY}"
          echo "GET $URL"
          body="$(curl -sS -w '\n%{http_code}\n' "$URL" || true)"
          http="$(echo "$body" | tail -n1)"
          payload="$(echo "$body" | head -n-1)"
          printf '%s\n' "$payload" > "$OPS/ls.json" || true
          echo "status=$http" >> "$GITHUB_OUTPUT"

          schema_ok="false"
          total=0
          if [ "$http" = "200" ] && jq -e '.files and (.files|type=="array")' "$OPS/ls.json" >/dev/null 2>&1; then
            schema_ok="true"
            total="$(jq '.files|length' "$OPS/ls.json")"
          fi
          echo "schema_ok=$schema_ok" >> "$GITHUB_OUTPUT"
          echo "total=$total" >> "$GITHUB_OUTPUT"

          jq -r '.files // [] | .[]' "$OPS/ls.json" | sort > "$OPS/files.list"

      - name: GET /get (index.json)
        id: get_index
        run: |
          set -euo pipefail
          pick="index.json"
          URL="${BASE}/wp-json/${NS}/get?site_key=${SITE_KEY}&file=${pick}"
          echo "GET $URL"
          body="$(curl -sS -w '\n%{http_code}\n' "$URL" || true)"
          http="$(echo "$body" | tail -n1)"
          content="$(echo "$body" | head -n-1)"
          printf '%s\n' "$content" > "$OPS/get.index.json" || true
          echo "status=$http" >> "$GITHUB_OUTPUT"
          if [ "$http" = "200" ]; then
            schema_ok=$(jq -e 'has("manifest") and has("options") and has("selftest")' "$OPS/get.index.json" >/dev/null 2>&1 && echo true || echo false)
          else
            schema_ok=false
          fi
          echo "schema_ok=$schema_ok" >> "$GITHUB_OUTPUT"

      - name: GET /get sample files_*.json
        id: get_samples
        run: |
          set -euo pipefail
          SAMPLED=0
          OK=0
          ERR=0
          > "$OPS/samples.txt"
          mapfile -t picks < <(grep -E '^files_[0-9]{3}\.json$' "$OPS/files.list" | head -n "$SAMPLE_N" || true)
          for f in "${picks[@]}"; do
            [ -z "$f" ] && continue
            URL="${BASE}/wp-json/${NS}/get?site_key=${SITE_KEY}&file=${f}"
            echo "GET $URL"
            body="$(curl -sS -w '\n%{http_code}\n' "$URL" || true)"
            http="$(echo "$body" | tail -n1)"
            content="$(echo "$body" | head -n-1)"
            printf '%s\n' "$content" > "$OPS/get.$f" || true
            SAMPLED=$((SAMPLED+1))
            if [ "$http" = "200" ] && jq -e 'type=="object" or type=="array"' "$OPS/get.$f" >/dev/null 2>&1; then
              echo "[OK] $f ($http)" >> "$OPS/samples.txt"
              OK=$((OK+1))
            else
              echo "[ERR] $f (http=$http, json?=$(jq -e . "$OPS/get.$f" >/dev/null 2>&1 && echo yes || echo no))" >> "$OPS/samples.txt"
              ERR=$((ERR+1))
            fi
          done
          echo "sampled=$SAMPLED" >> "$GITHUB_OUTPUT"
          echo "ok=$OK" >> "$GITHUB_OUTPUT"
          echo "err=$ERR" >> "$GITHUB_OUTPUT"

      - name: Load previous state (if any)
        id: prev
        run: |
          set -euo pipefail
          if [ -f "$STATE_FILE" ]; then
            cp "$STATE_FILE" "$OPS/prev-files.list"
          else
            : > "$OPS/prev-files.list"
          fi
          echo "has_prev=$( [ -s "$OPS/prev-files.list" ] && echo yes || echo no )" >> "$GITHUB_OUTPUT"

      - name: Compute delta
        id: delta
        run: |
          set -euo pipefail
          comm -13 "$OPS/prev-files.list" "$OPS/files.list" > "$OPS/added.list"  || true
          comm -23 "$OPS/prev-files.list" "$OPS/files.list" > "$OPS/removed.list" || true
          ADDED=$(wc -l < "$OPS/added.list"  | tr -d ' ')
          REM=$(wc -l < "$OPS/removed.list" | tr -d ' ')
          DIFF=$((ADDED + REM))
          echo "added=$ADDED"   >> "$GITHUB_OUTPUT"
          echo "removed=$REM"   >> "$GITHUB_OUTPUT"
          echo "delta=$DIFF"    >> "$GITHUB_OUTPUT"

      # ========= ZAMIANA jq --argfile -> Python (brak zależności od opcji jq) =========
      - name: Decide result (Python)
        id: decide
        env:
          H: ${{ steps.health.outputs.status }}
          HJSON: ${{ steps.health.outputs.ok_json }}
          L: ${{ steps.ls.outputs.status }}
          LOK: ${{ steps.ls.outputs.schema_ok }}
          T: ${{ steps.ls.outputs.total }}
          GI: ${{ steps.get_index.outputs.status }}
          GI_SCHEMA: ${{ steps.get_index.outputs.schema_ok }}
          SAMP: ${{ steps.get_samples.outputs.sampled }}
          SOK: ${{ steps.get_samples.outputs.ok }}
          SERR: ${{ steps.get_samples.outputs.err }}
          ADDED: ${{ steps.delta.outputs.added }}
          REMOVED: ${{ steps.delta.outputs.removed }}
          DELTA: ${{ steps.delta.outputs.delta }}
          HARD: ${{ env.DELTA_HARD_LIMIT }}
        run: |
          python3 - << 'PY'
          import os, json
          OPS="ops-snapshot-watchdog"
          # parse env with defaults
          H=int(os.getenv("H","0") or "0")
          HJSON=os.getenv("HJSON","no")
          L=int(os.getenv("L","0") or "0")
          LOK=os.getenv("LOK","false")=="true"
          T=int(os.getenv("T","0") or "0")
          GI=int(os.getenv("GI","0") or "0")
          GI_SCHEMA=os.getenv("GI_SCHEMA","false")=="true"
          SAMP=int(os.getenv("SAMP","0") or "0")
          SOK=int(os.getenv("SOK","0") or "0")
          SERR=int(os.getenv("SERR","0") or "0")
          ADDED=int(os.getenv("ADDED","0") or "0")
          REMOVED=int(os.getenv("REMOVED","0") or "0")
          DELTA=int(os.getenv("DELTA","0") or "0")
          HARD=int(os.getenv("HARD","5") or "5")

          def load_json(path):
            try:
              with open(path,'r',encoding='utf-8') as f:
                return json.load(f)
            except Exception:
              return None

          health = load_json(f"{OPS}/health.json")
          ls = load_json(f"{OPS}/ls.json")

          status="ok"; reason="healthy"
          if H!=200 or HJSON!="yes":
            status="fail"; reason="health_bad_http_or_json"
          elif L!=200 or not LOK:
            status="fail"; reason="ls_bad_or_schema"
          elif T==0:
            status="fail"; reason="ls_empty_files"
          elif GI!=200 or not GI_SCHEMA:
            status="fail"; reason="index_bad_http_or_schema"
          elif SERR>0:
            status="fail"; reason="sample_get_errors"
          elif DELTA>HARD:
            status="fail"; reason="delta_exceeds_limit"

          summary = {
            "status": status,
            "reason": reason,
            "totals": {"files": T, "delta": DELTA, "added": ADDED, "removed": REMOVED},
            "checks": {
              "health": {"http": H, "ok_json": HJSON},
              "ls": {"http": L, "schema_ok": LOK},
              "index": {"http": GI, "schema_ok": GI_SCHEMA},
              "samples": {"sampled": SAMP, "ok": SOK, "err": SERR}
            },
            "health": health,
            "ls": ls
          }
          os.makedirs(OPS, exist_ok=True)
          with open(f"{OPS}/summary.json","w",encoding="utf-8") as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
          print(json.dumps({"write":"ok","status":status,"reason":reason}))
          # expose fail flag via GITHUB_OUTPUT
          fail = "true" if status!="ok" else "false"
          with open(os.environ["GITHUB_OUTPUT"],"a") as out:
            out.write(f"fail={fail}\n")
          PY

      - name: Persist state (files list) to repo
        if: ${{ steps.decide.outputs.fail == 'false' }}
        run: |
          set -euo pipefail
          cp "$OPS/files.list" "$STATE_FILE"
          if ! git diff --quiet -- "$STATE_FILE"; then
            git config user.name  "wtp-bot"
            git config user.email "wtp-bot@users.noreply.github.com"
            git add "$STATE_FILE"
            git commit -m "watchdog: update snapshot files state ($(date -u +%FT%TZ))"
            git push origin HEAD:main
          else
            echo "State unchanged."
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: snapshot-watchdog
          path: ops-snapshot-watchdog/**
          if-no-files-found: warn
          retention-days: 7

      - name: Create Issue on failure
        if: ${{ steps.decide.outputs.fail == 'true' }}
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = 'Snapshot watchdog detected a problem.\n\n';
            try {
              const summary = JSON.parse(fs.readFileSync('ops-snapshot-watchdog/summary.json','utf8'));
              body += '### Summary\njson\n' + JSON.stringify(summary, null, 2).slice(0, 5000) + '\n\n';
            } catch (e) {
              body += 'No summary available.\n';
            }
            const added = fs.existsSync('ops-snapshot-watchdog/added.list') ? fs.readFileSync('ops-snapshot-watchdog/added.list','utf8') : '';
            const removed = fs.existsSync('ops-snapshot-watchdog/removed.list') ? fs.readFileSync('ops-snapshot-watchdog/removed.list','utf8') : '';
            body += '\n### Delta\n';
            body += '*Added:*\n\n' + added.slice(0,2000) + '\n\n';
            body += '*Removed:*\n\n' + removed.slice(0,2000) + '\n\n';
            body += \nRun: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId};
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: ❌ Snapshot Watchdog failed (${new Date().toISOString()}),
              body
            });

      - name: Fail job if watchdog failed
        if: ${{ steps.decide.outputs.fail == 'true' }}
        run: |
          echo "::error::Snapshot watchdog failed (see artifacts and issue)."
          exit 1
