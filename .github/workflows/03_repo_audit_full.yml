name: 03_repo_audit_full (read-only, complete)

on:
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: repo-audit-full
  cancel-in-progress: true

jobs:
  audit:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      RUN_ID: ${{ github.run_id }}
      OUT: .wtp/state/ro/public/${{ github.run_id }}/repo
      LATEST: .wtp/state/ro/public/latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Ensure dirs
        run: |
          set -euo pipefail
          mkdir -p "_out/repo_audit/${RUN_ID}" "${OUT}" "${LATEST}/repo"

      - name: Build file/workflow indexes
        run: |
          set -euo pipefail
          git ls-files -co --exclude-standard > "_out/repo_audit/${RUN_ID}/filelist.txt"
          ls -laR > "_out/repo_audit/${RUN_ID}/tree.txt"
          python - << 'PY'
          import os, glob, json, yaml, pathlib
          rid = os.environ["RUN_ID"]
          out = pathlib.Path(f"_out/repo_audit/{rid}")
          out.mkdir(parents=True, exist_ok=True)
          items=[]
          for p in sorted(glob.glob(".github/workflows/*.yml")):
              try:
                  with open(p, "r", encoding="utf-8") as f:
                      y = yaml.safe_load(f) or {}
              except Exception as e:
                  y = {"_parse_error": str(e)}
              items.append({
                  "file": os.path.basename(p),
                  "name": y.get("name", os.path.basename(p)),
                  "on": y.get("on"),
                  "jobs": list((y.get("jobs") or {}).keys())
              })
          (out/"workflows.json").write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")
          with open(out/"workflows.md","w",encoding="utf-8") as f:
              f.write("# Workflows index\n\n")
              for w in items:
                  f.write(f"## {w['name']} ({w['file']})\n")
                  f.write(f"- Triggers: `{w['on']}`\n")
                  f.write(f"- Jobs: {', '.join(w['jobs']) if w['jobs'] else '-'}\n\n")
          PY

      - name: Scan repo -> plugin/mu meta + hooks/symbols/includes (canonical + legacy)
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, re, json
          from pathlib import Path

          RUN_ID = os.environ["RUN_ID"]
          OUT = Path(os.environ["OUT"])
          AUX = Path(f"_out/repo_audit/{RUN_ID}")
          OUT.mkdir(parents=True, exist_ok=True)

          # --- ŚCIEŻKI (kanoniczne i legacy obecne w repo) ---
          MU_PATHS       = [Path("wp-content/mu-plugins"), Path("mu-plugins")]
          PLUGINS_PATHS  = [Path("wp-content/plugins"), Path("plugins")]
          THEMES_PATHS   = [Path("wp-content/themes"), Path("themes")]
          EXTRA_SCAN     = [Path(".wtp"), Path("inc"), Path("includes")]

          def walk_php(paths):
              for base in paths:
                  if not base.exists():
                      continue
                  for f in base.rglob("*.php"):
                      s = str(f)
                      if "/vendor/" in s or "/node_modules/" in s:
                          continue
                      yield f

          header_line = re.compile(r"^\s*(?P<key>[A-Za-z][A-Za-z \-]+):\s*(?P<val>.+)\s*$")
          def parse_headers(php_file):
              headers={}
              try:
                  with open(php_file, "r", encoding="utf-8", errors="ignore") as f:
                      for i,ln in enumerate(f):
                          if i>120: break
                          m = header_line.match(ln)
                          if m:
                              headers[m.group("key").strip()] = m.group("val").strip()
              except Exception:
                  pass
              return headers

          def plugin_record(path, headers, kind, root_label):
              return {
                  "kind": kind,                # plugin / mu
                  "path": str(path),
                  "root": root_label,         # np. mu-canon / mu-legacy / plugins-canon / plugins-legacy
                  "name": headers.get("Plugin Name"),
                  "plugin_uri": headers.get("Plugin URI"),
                  "description": headers.get("Description"),
                  "version": headers.get("Version"),
                  "author": headers.get("Author"),
                  "author_uri": headers.get("Author URI"),
                  "text_domain": headers.get("Text Domain"),
                  "domain_path": headers.get("Domain Path"),
                  "requires_wp": headers.get("Requires at least"),
                  "tested_wp": headers.get("Tested up to"),
                  "requires_php": headers.get("Requires PHP"),
                  "network": headers.get("Network"),
              }

          # -------- Regular plugins meta (kanoniczne + legacy) --------
          plugin_meta = []
          for base in PLUGINS_PATHS:
              if not base.exists():
                  continue
              root_label = "plugins-canon" if "wp-content" in str(base) else "plugins-legacy"
              for entry in sorted(base.iterdir()):
                  if entry.is_dir():
                      found = False
                      # szukaj pliku głównego w katalogu
                      for p in entry.glob("*.php"):
                          h = parse_headers(p)
                          if "Plugin Name" in h:
                              plugin_meta.append(plugin_record(p, h, "plugin", root_label))
                              found = True
                              break
                      if not found:
                          for p in entry.rglob("*.php"):
                              h = parse_headers(p)
                              if "Plugin Name" in h:
                                  plugin_meta.append(plugin_record(p, h, "plugin", root_label))
                                  break
                  elif entry.is_file() and entry.suffix == ".php":
                      h = parse_headers(entry)
                      if "Plugin Name" in h:
                          plugin_meta.append(plugin_record(entry, h, "plugin", root_label))

          # -------- MU plugins meta (kanoniczne + legacy) --------
          mu_meta = []
          for base in MU_PATHS:
              if not base.exists():
                  continue
              root_label = "mu-canon" if "wp-content" in str(base) else "mu-legacy"
              for p in sorted(base.rglob("*.php")):
                  h = parse_headers(p)
                  mu_meta.append(plugin_record(p, h, "mu", root_label))

          # -------- Hooki / symbole / includes z całości (plugins, mu, themes, extra) --------
          hook_calls = []
          sym_index = {"functions": [], "classes": []}
          includes = []

          re_add_action  = re.compile(r"\badd_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_add_filter  = re.compile(r"\badd_filter\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_do_action   = re.compile(r"\bdo_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_apply_filt  = re.compile(r"\bapply_filters\s*\(\s*['\"]([^'\"]+)['\"]", re.I)

          re_func  = re.compile(r"\bfunction\s+([a-zA-Z0-9_]+)\s*\(", re.I)
          re_class = re.compile(r"\bclass\s+([a-zA-Z0-9_]+)\b", re.I)

          re_inc = re.compile(r"\b(require|require_once|include|include_once)\s*\(\s*['\"]([^'\"]+)['\"]\s*\)", re.I)

          SCAN_ROOTS = PLUGINS_PATHS + MU_PATHS + THEMES_PATHS + EXTRA_SCAN
          for php in walk_php(SCAN_ROOTS):
              try:
                  src = php.read_text(encoding="utf-8", errors="ignore")
              except Exception:
                  continue

              for m in re_add_action.finditer(src):
                  hook_calls.append({"type":"add_action","hook":m.group(1),"file":str(php)})
              for m in re_add_filter.finditer(src):
                  hook_calls.append({"type":"add_filter","hook":m.group(1),"file":str(php)})
              for m in re_do_action.finditer(src):
                  hook_calls.append({"type":"do_action","hook":m.group(1),"file":str(php)})
              for m in re_apply_filt.finditer(src):
                  hook_calls.append({"type":"apply_filters","hook":m.group(1),"file":str(php)})

              for m in re_func.finditer(src):
                  sym_index["functions"].append({"name":m.group(1),"file":str(php)})
              for m in re_class.finditer(src):
                  sym_index["classes"].append({"name":m.group(1),"file":str(php)})

              for m in re_inc.finditer(src):
                  includes.append({"type":m.group(1),"target":m.group(2),"file":str(php)})

          # -------- Zapis wyników --------
          OUT.joinpath("plugin_meta.json").write_text(json.dumps(plugin_meta, ensure_ascii=False, indent=2), encoding="utf-8")
          OUT.joinpath("mu_meta.json").write_text(json.dumps(mu_meta, ensure_ascii=False, indent=2), encoding="utf-8")
          OUT.joinpath("hooks.json").write_text(json.dumps(hook_calls, ensure_ascii=False, indent=2), encoding="utf-8")
          OUT.joinpath("symbol_index.json").write_text(json.dumps(sym_index, ensure_ascii=False, indent=2), encoding="utf-8")
          OUT.joinpath("includes_index.json").write_text(json.dumps(includes, ensure_ascii=False, indent=2), encoding="utf-8")

          repo_audit = {
              "run_id": RUN_ID,
              "counts": {
                  "plugins": len(plugin_meta),
                  "mu_plugins": len(mu_meta),
                  "hooks": len(hook_calls),
                  "functions": len(sym_index["functions"]),
                  "classes": len(sym_index["classes"]),
                  "includes": len(includes)
              }
          }
          OUT.joinpath("repo-audit.json").write_text(json.dumps(repo_audit, ensure_ascii=False, indent=2), encoding="utf-8")

          md = []
          md.append("# REPO AUDIT (full)")
          md.append(f"- Run ID: {RUN_ID}")
          md.append("")
          md.append("## Totals")
          for k,v in repo_audit["counts"].items():
              md.append(f"- {k}: **{v}**")
          md.append("")
          md.append("## Notes")
          md.append("- Scanned canonical + legacy paths for plugins, MU-plugins, and themes.")
          md.append("- Headers parsed from PHP tops; hooks/symbols/includes are grep-based.")
          OUT.joinpath("REPO_AUDIT.md").write_text("\n".join(md)+"\n", encoding="utf-8")

          # --- publikacja stałych linków w latest ---
          latest = Path(os.environ["LATEST"])
          latest.mkdir(parents=True, exist_ok=True)
          (latest/"repo").mkdir(parents=True, exist_ok=True)

          # indeksy pomocnicze
          for src, dst in [
              (AUX/"filelist.txt", latest/"filelist.txt"),
              (AUX/"tree.txt", latest/"tree.txt"),
              (AUX/"workflows.json", latest/"workflows.json"),
              (AUX/"workflows.md", latest/"workflows.md"),
          ]:
              if src.exists():
                  dst.write_text(src.read_text(encoding="utf-8"), encoding="utf-8")

          # repo outputs
          for name in ["REPO_AUDIT.md","repo-audit.json","plugin_meta.json","mu_meta.json","hooks.json","symbol_index.json","includes_index.json"]:
              src = OUT/name
              dst = latest/"repo"/name
              if src.exists():
                  dst.write_text(src.read_text(encoding="utf-8"), encoding="utf-8")
          PY

      - name: Commit & push (rebase-safe)
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --staged --quiet; then
            echo "::notice::Nothing to commit."
            exit 0
          fi
          git commit -m "repo audit (full) ${RUN_ID}"
          BRANCH="${GITHUB_REF_NAME:-main}"
          git branch --show-current >/dev/null 2>&1 || git checkout -B "$BRANCH"
          for i in 1 2 3; do
            git fetch origin "$BRANCH"
            git pull --rebase origin "$BRANCH" || { git rebase --continue || true; }
            if git push origin "HEAD:$BRANCH"; then
              echo "::notice::Pushed (attempt $i)"
              exit 0
            fi
            sleep 2
          done
          echo "::error::Push failed after 3 attempts"
          exit 1
