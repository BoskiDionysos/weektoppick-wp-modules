name: 03_repo_audit_full (read-only, complete)

on:
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: repo-audit-full
  cancel-in-progress: true

jobs:
  audit:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      RUN_ID: ${{ github.run_id }}
      OUT: .wtp/state/ro/public/${{ github.run_id }}/repo
      LATEST: .wtp/state/ro/public/latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Ensure dirs
        run: |
          set -euo pipefail
          mkdir -p "_out/repo_audit/${RUN_ID}" "${OUT}" "${LATEST}/repo"

      - name: Build file/workflow indexes
        run: |
          set -euo pipefail
          git ls-files -co --exclude-standard > "_out/repo_audit/${RUN_ID}/filelist.txt"
          ls -laR > "_out/repo_audit/${RUN_ID}/tree.txt"
          python - << 'PY'
          import os, glob, json, yaml, pathlib
          rid = os.environ["RUN_ID"]
          out = pathlib.Path(f"_out/repo_audit/{rid}")
          items=[]
          for p in sorted(glob.glob(".github/workflows/*.yml")):
              try:
                  y = yaml.safe_load(open(p,encoding="utf-8")) or {}
              except Exception as e:
                  y = {"_parse_error": str(e)}
              items.append({
                  "file": os.path.basename(p),
                  "name": y.get("name", os.path.basename(p)),
                  "on": y.get("on"),
                  "jobs": list((y.get("jobs") or {}).keys())
              })
          (out/"workflows.json").write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")
          with open(out/"workflows.md","w",encoding="utf-8") as f:
              f.write("# Workflows index\n\n")
              for w in items:
                  f.write(f"## {w['name']} ({w['file']})\n- Triggers: `{w['on']}`\n- Jobs: {', '.join(w['jobs']) if w['jobs'] else '-'}\n\n")
          PY

      - name: Scan repo -> plugin/mu meta + hooks/symbols/includes + deps
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, re, json
          from pathlib import Path

          RUN_ID = os.environ["RUN_ID"]
          OUT = Path(os.environ["OUT"])
          LATEST = Path(os.environ["LATEST"])
          AUX = Path(f"_out/repo_audit/{RUN_ID}")
          OUT.mkdir(parents=True, exist_ok=True)

          def walk_php(paths):
              for base in paths:
                  p = Path(base)
                  if not p.exists(): continue
                  for f in p.rglob("*.php"):
                      s = str(f)
                      if "/vendor/" in s or "/node_modules/" in s: continue
                      yield f

          hdr = re.compile(r"^\s*(?P<key>[A-Za-z][A-Za-z \-]+):\s*(?P<val>.+?)\s*$")
          def parse_headers(fp):
              h={}
              try:
                  with open(fp,"r",encoding="utf-8",errors="ignore") as f:
                      for i,ln in enumerate(f):
                          if i>60: break
                          m=hdr.match(ln)
                          if m: h[m.group("key").strip()] = m.group("val").strip()
              except Exception: pass
              return h

          def rec(path,headers,kind):
              return {
                "kind": kind, "path": str(path),
                "name": headers.get("Plugin Name"),
                "plugin_uri": headers.get("Plugin URI"),
                "description": headers.get("Description"),
                "version": headers.get("Version"),
                "author": headers.get("Author"),
                "author_uri": headers.get("Author URI"),
                "text_domain": headers.get("Text Domain"),
                "requires_wp": headers.get("Requires at least"),
                "requires_php": headers.get("Requires PHP"),
              }

          # plugins in BOTH layouts: plugins/ and wp-content/plugins/
          plugin_meta=[]
          for base in ["plugins","wp-content/plugins"]:
              bp=Path(base)
              if not bp.exists(): continue
              for entry in sorted(bp.iterdir()):
                  if entry.is_dir():
                      # guess main file
                      main=None
                      for cand in list(entry.glob("*.php")) + list(entry.rglob("*.php")):
                          h=parse_headers(cand)
                          if "Plugin Name" in h:
                              main=cand; plugin_meta.append(rec(main,h,"plugin")); break
                  elif entry.suffix==".php":
                      h=parse_headers(entry)
                      if "Plugin Name" in h: plugin_meta.append(rec(entry,h,"plugin"))

          # mu-plugins in BOTH layouts: mu-plugins/ and wp-content/mu-plugins/
          mu_meta=[]
          for base in ["mu-plugins","wp-content/mu-plugins"]:
              bp=Path(base)
              if not bp.exists(): continue
              for f in bp.rglob("*.php"):
                  mu_meta.append(rec(f, parse_headers(f), "mu"))

          # hooks / symbols / includes
          hook_calls=[]
          sym={"functions":[], "classes":[]}
          includes=[]

          re_add_action  = re.compile(r"\badd_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_add_filter  = re.compile(r"\badd_filter\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_do_action   = re.compile(r"\bdo_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_apply_filt  = re.compile(r"\bapply_filters\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_func = re.compile(r"\bfunction\s+([A-Za-z0-9_]+)\s*\(", re.I)
          re_class = re.compile(r"\bclass\s+([A-Za-z0-9_]+)\b", re.I)
          re_inc = re.compile(r"\b(require|require_once|include|include_once)\s*\(\s*['\"]([^'\"]+)['\"]\s*\)", re.I)

          scan_roots=["plugins","wp-content/plugins","mu-plugins","wp-content/mu-plugins","wp-content/themes",".wtp","inc","includes"]
          for php in walk_php(scan_roots):
              try: src=php.read_text(encoding="utf-8",errors="ignore")
              except Exception: continue
              for m in re_add_action.finditer(src):  hook_calls.append({"type":"add_action","hook":m.group(1),"file":str(php)})
              for m in re_add_filter.finditer(src):  hook_calls.append({"type":"add_filter","hook":m.group(1),"file":str(php)})
              for m in re_do_action.finditer(src):   hook_calls.append({"type":"do_action","hook":m.group(1),"file":str(php)})
              for m in re_apply_filt.finditer(src):  hook_calls.append({"type":"apply_filters","hook":m.group(1),"file":str(php)})
              for m in re_func.finditer(src):        sym["functions"].append({"name":m.group(1),"file":str(php)})
              for m in re_class.finditer(src):       sym["classes"].append({"name":m.group(1),"file":str(php)})
              for m in re_inc.finditer(src):         includes.append({"type":m.group(1),"target":m.group(2),"file":str(php)})

          # simple dependency map (per file -> included targets)
          deps={}
          for inc in includes:
              deps.setdefault(inc["file"], []).append(inc["target"])

          # write
          (OUT/"plugin_meta.json").write_text(json.dumps(plugin_meta,ensure_ascii=False,indent=2),encoding="utf-8")
          (OUT/"mu_meta.json").write_text(json.dumps(mu_meta,ensure_ascii=False,indent=2),encoding="utf-8")
          (OUT/"hooks.json").write_text(json.dumps(hook_calls,ensure_ascii=False,indent=2),encoding="utf-8")
          (OUT/"symbol_index.json").write_text(json.dumps(sym,ensure_ascii=False,indent=2),encoding="utf-8")
          (OUT/"includes_index.json").write_text(json.dumps(includes,ensure_ascii=False,indent=2),encoding="utf-8")
          (OUT/"dependencies.json").write_text(json.dumps(deps,ensure_ascii=False,indent=2),encoding="utf-8")

          agg={
            "run_id": RUN_ID,
            "counts":{
              "plugins":len(plugin_meta),"mu_plugins":len(mu_meta),
              "hooks":len(hook_calls),"functions":len(sym["functions"]),
              "classes":len(sym["classes"]),"includes":len(includes)
            }
          }
          (OUT/"repo-audit.json").write_text(json.dumps(agg,ensure_ascii=False,indent=2),encoding="utf-8")

          md=["# REPO AUDIT (full)", f"- Run ID: {RUN_ID}", "", "## Totals"]
          for k,v in agg["counts"].items(): md.append(f"- {k}: **{v}**")
          (OUT/"REPO_AUDIT.md").write_text("\n".join(md)+"\n",encoding="utf-8")

          # sanity (fail if clearly empty)
          if agg["counts"]["mu_plugins"]==0 and agg["counts"]["plugins"]==0:
              raise SystemExit("::error::No plugins or MU-plugins detected in repo layout (plugins/, mu-plugins/).")

          # copy stable indexes to latest
          LATEST.mkdir(parents=True, exist_ok=True); (LATEST/"repo").mkdir(parents=True,exist_ok=True)
          for src,dst in [
            (Path(f"_out/repo_audit/{RUN_ID}/filelist.txt"), LATEST/"filelist.txt"),
            (Path(f"_out/repo_audit/{RUN_ID}/tree.txt"),     LATEST/"tree.txt"),
            (Path(f"_out/repo_audit/{RUN_ID}/workflows.json"), LATEST/"workflows.json"),
            (Path(f"_out/repo_audit/{RUN_ID}/workflows.md"),   LATEST/"workflows.md"),
          ]:
              if src.exists(): dst.write_text(src.read_text(encoding="utf-8"),encoding="utf-8")
          for name in ["REPO_AUDIT.md","repo-audit.json","plugin_meta.json","mu_meta.json","hooks.json","symbol_index.json","includes_index.json","dependencies.json"]:
              p=OUT/name
              (LATEST/"repo"/name).write_text(p.read_text(encoding="utf-8"),encoding="utf-8")
          PY

      - name: Commit & push (rebase-safe)
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          git diff --staged --quiet || git commit -m "repo audit (full) ${RUN_ID}"
          BRANCH="${GITHUB_REF_NAME:-main}"
          git branch --show-current >/dev/null 2>&1 || git checkout -B "$BRANCH"
          for i in 1 2 3; do
            git fetch origin "$BRANCH"
            git pull --rebase origin "$BRANCH" || { git rebase --continue || true; }
            git push origin "HEAD:$BRANCH" && exit 0
            sleep 2
          done
          echo "::error::Push failed after 3 attempts"; exit 1
