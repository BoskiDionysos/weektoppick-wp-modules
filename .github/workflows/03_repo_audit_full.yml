name: 03_repo_audit_full (read-only, complete)

on:
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: repo-audit-full
  cancel-in-progress: true

jobs:
  audit:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      RUN_ID: ${{ github.run_id }}
      OUT: .wtp/state/ro/public/${{ github.run_id }}/repo
      LATEST: .wtp/state/ro/public/latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install pyyaml

      - name: Ensure dirs
        run: |
          set -euo pipefail
          mkdir -p "_out/repo_audit/${RUN_ID}" "${OUT}" "${LATEST}/repo"

      - name: Build file/workflow indexes
        run: |
          set -euo pipefail
          git ls-files -co --exclude-standard > "_out/repo_audit/${RUN_ID}/filelist.txt"
          ls -laR > "_out/repo_audit/${RUN_ID}/tree.txt"
          python - << 'PY'
          import os, glob, json, yaml, pathlib
          rid = os.environ["RUN_ID"]
          out = pathlib.Path(f"_out/repo_audit/{rid}")
          out.mkdir(parents=True, exist_ok=True)
          items=[]
          for p in sorted(glob.glob(".github/workflows/*.yml")):
              try:
                  with open(p, "r", encoding="utf-8") as f:
                      y = yaml.safe_load(f) or {}
              except Exception as e:
                  y = {"_parse_error": str(e)}
              items.append({
                  "file": os.path.basename(p),
                  "name": y.get("name", os.path.basename(p)),
                  "on": y.get("on"),
                  "jobs": list((y.get("jobs") or {}).keys())
              })
          (out/"workflows.json").write_text(json.dumps(items, ensure_ascii=False, indent=2), encoding="utf-8")
          with open(out/"workflows.md","w",encoding="utf-8") as f:
              f.write("# Workflows index\n\n")
              for w in items:
                  f.write(f"## {w['name']} ({w['file']})\n")
                  f.write(f"- Triggers: `{w['on']}`\n")
                  f.write(f"- Jobs: {', '.join(w['jobs']) if w['jobs'] else '-'}\n\n")
          PY

      - name: Scan repo → plugin/mu meta + hooks/symbols/includes + dependencies
        run: |
          set -euo pipefail
          python - << 'PY'
          import os, re, json
          from pathlib import Path

          RUN_ID = os.environ["RUN_ID"]
          OUT = Path(os.environ["OUT"])
          AUX = Path(f"_out/repo_audit/{RUN_ID}")
          LATEST = Path(os.environ["LATEST"])
          OUT.mkdir(parents=True, exist_ok=True)
          (LATEST/"repo").mkdir(parents=True, exist_ok=True)

          # ---------- helpers ----------
          def first_n_lines(p: Path, n=60):
              try:
                  with p.open("r", encoding="utf-8", errors="ignore") as f:
                      return [next(f) for _ in range(n)]
              except StopIteration:
                  return []
              except Exception:
                  return []

          header_line = re.compile(r"^\s*(?P<key>[A-Za-z][A-Za-z \-]+):\s*(?P<val>.+)\s*$")
          def parse_headers(php_file: Path):
              headers = {}
              for ln in first_n_lines(php_file, 80):
                  m = header_line.match(ln)
                  if m:
                      k = m.group("key").strip()
                      v = m.group("val").strip()
                      headers[k] = v
              return headers

          def plugin_record(path: Path, headers: dict, kind: str):
              return {
                  "kind": kind, "path": str(path),
                  "name": headers.get("Plugin Name"),
                  "plugin_uri": headers.get("Plugin URI"),
                  "description": headers.get("Description"),
                  "version": headers.get("Version"),
                  "author": headers.get("Author"),
                  "author_uri": headers.get("Author URI"),
                  "text_domain": headers.get("Text Domain"),
                  "domain_path": headers.get("Domain Path"),
                  "requires_wp": headers.get("Requires at least"),
                  "tested_wp": headers.get("Tested up to"),
                  "requires_php": headers.get("Requires PHP"),
                  "network": headers.get("Network"),
              }

          def scan_plugins_dir(base: Path, kind="plugin"):
              out = []
              if not base.exists(): 
                  return out
              for entry in sorted(base.iterdir()):
                  if entry.is_dir():
                      # szukamy pliku głównego z "Plugin Name:"
                      found = False
                      for p in entry.glob("*.php"):
                          h = parse_headers(p)
                          if "Plugin Name" in h:
                              out.append(plugin_record(p, h, kind))
                              found = True
                              break
                      if not found:
                          for p in entry.rglob("*.php"):
                              h = parse_headers(p)
                              if "Plugin Name" in h:
                                  out.append(plugin_record(p, h, kind))
                                  break
                  elif entry.is_file() and entry.suffix == ".php":
                      h = parse_headers(entry)
                      if "Plugin Name" in h:
                          out.append(plugin_record(entry, h, kind))
              return out

          # ---------- collect plugin_meta (regular plugins) ----------
          plugin_meta = []
          for d in [Path("wp-content/plugins"), Path("plugins")]:
              plugin_meta.extend(scan_plugins_dir(d, "plugin"))

          # ---------- collect mu_meta ----------
          mu_meta = []
          for d in [Path("wp-content/mu-plugins"), Path("mu-plugins")]:
              if d.exists():
                  for p in sorted(d.rglob("*.php")):
                      h = parse_headers(p)
                      mu_meta.append(plugin_record(p, h, "mu"))

          # ---------- hooks / symbols / includes ----------
          hook_calls = []
          sym_index = {"functions": [], "classes": []}
          includes = []

          re_add_action  = re.compile(r"\badd_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_add_filter  = re.compile(r"\badd_filter\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_do_action   = re.compile(r"\bdo_action\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_apply_filt  = re.compile(r"\bapply_filters\s*\(\s*['\"]([^'\"]+)['\"]", re.I)
          re_func        = re.compile(r"\bfunction\s+([a-zA-Z0-9_]+)\s*\(", re.I)
          re_class       = re.compile(r"\bclass\s+([a-zA-Z0-9_]+)\b", re.I)
          re_inc         = re.compile(r"\b(require|require_once|include|include_once)\s*\(\s*['\"]([^'\"]+)['\"]\s*\)", re.I)

          scan_roots = [
              "wp-content/plugins", "plugins",
              "wp-content/mu-plugins", "mu-plugins",
              "wp-content/themes", "themes",
              ".wtp", "inc", "includes"
          ]

          def walk_php():
              for root in scan_roots:
                  d = Path(root)
                  if not d.exists(): 
                      continue
                  for p in d.rglob("*.php"):
                      if "/vendor/" in str(p) or "/node_modules/" in str(p):
                          continue
                      yield p

          for php in walk_php():
              try:
                  src = php.read_text(encoding="utf-8", errors="ignore")
              except Exception:
                  continue

              for m in re_add_action.finditer(src):
                  hook_calls.append({"type":"add_action","hook":m.group(1),"file":str(php)})
              for m in re_add_filter.finditer(src):
                  hook_calls.append({"type":"add_filter","hook":m.group(1),"file":str(php)})
              for m in re_do_action.finditer(src):
                  hook_calls.append({"type":"do_action","hook":m.group(1),"file":str(php)})
              for m in re_apply_filt.finditer(src):
                  hook_calls.append({"type":"apply_filters","hook":m.group(1),"file":str(php)})

              for m in re_func.finditer(src):
                  sym_index["functions"].append({"name":m.group(1),"file":str(php)})
              for m in re_class.finditer(src):
                  sym_index["classes"].append({"name":m.group(1),"file":str(php)})

              for m in re_inc.finditer(src):
                  includes.append({"type":m.group(1),"target":m.group(2),"file":str(php)})

          # ---------- dependencies (na bazie includes) ----------
          deps = {}
          for inc in includes:
              src = inc["file"]
              dst = inc["target"]
              deps.setdefault(src, set()).add(dst)
          deps = {k: sorted(v) for k,v in deps.items()}

          # ---------- write outputs ----------
          def dump(obj, name):
              (OUT/name).write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")
              (LATEST/"repo"/name).write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

          dump(plugin_meta, "plugin_meta.json")
          dump(mu_meta, "mu_meta.json")
          dump(hook_calls, "hooks.json")
          dump(sym_index, "symbol_index.json")
          dump(includes, "includes_index.json")
          dump(deps, "dependencies.json")

          repo_audit = {
              "run_id": RUN_ID,
              "counts": {
                  "plugins": len(plugin_meta),
                  "mu_plugins": len(mu_meta),
                  "hooks": len(hook_calls),
                  "functions": len(sym_index["functions"]),
                  "classes": len(sym_index["classes"]),
                  "includes": len(includes)
              }
          }
          dump(repo_audit, "repo-audit.json")

          md = []
          md.append("# REPO AUDIT (full)")
          md.append(f"- Run ID: {RUN_ID}")
          md.append("")
          md.append("## Totals")
          for k,v in repo_audit["counts"].items():
              md.append(f"- {k}: **{v}**")
          md.append("")
          md.append("## Notes")
          md.append("- Scanned paths: wp-content/plugins, plugins/, wp-content/mu-plugins, mu-plugins/, themes/, .wtp/, inc/, includes/")
          md_txt = "\n".join(md) + "\n"
          (OUT/"REPO_AUDIT.md").write_text(md_txt, encoding="utf-8")
          (LATEST/"repo"/"REPO_AUDIT.md").write_text(md_txt, encoding="utf-8")

          # lekkie indeksy → latest
          for src, dst in [
              (AUX/"filelist.txt", LATEST/"filelist.txt"),
              (AUX/"tree.txt", LATEST/"tree.txt"),
              (AUX/"workflows.json", LATEST/"workflows.json"),
              (AUX/"workflows.md", LATEST/"workflows.md"),
          ]:
              if src.exists():
                  dst.write_text(src.read_text(encoding="utf-8"), encoding="utf-8")
          PY

      - name: Commit & push (rebase-safe)
        run: |
          set -euo pipefail
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --staged --quiet; then
            echo "::notice::Nothing to commit."
            exit 0
          fi
          git commit -m "repo audit (full) ${RUN_ID}"
          BRANCH="${GITHUB_REF_NAME:-main}"
          git branch --show-current >/dev/null 2>&1 || git checkout -B "$BRANCH"
          for i in 1 2 3; do
            git fetch origin "$BRANCH"
            git pull --rebase origin "$BRANCH" || { git rebase --continue || true; }
            if git push origin "HEAD:$BRANCH"; then
              echo "::notice::Pushed (attempt $i)"
              exit 0
            fi
            sleep 2
          done
          echo "::error::Push failed after 3 attempts"
          exit 1
