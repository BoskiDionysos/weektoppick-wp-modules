name: 03_repo_audit

on:
  workflow_dispatch: {}

permissions:
  contents: write

concurrency:
  group: repo-audit
  cancel-in-progress: true

jobs:
  audit:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    env:
      RUN_ID: ${{ github.run_id }}

    steps:
      - name: 1) Checkout
        uses: actions/checkout@v4

      - name: 2) Sanity – wejście istnieje?
        run: |
          set -euo pipefail
          IN=".wtp/state/ro/public/latest/repo/repo-snapshot.json"
          if [[ ! -f "$IN" ]]; then
            echo "::error::Brak $IN (najpierw uruchom 03_repo_snapshot)"
            exit 1
          fi
          head -n 3 "$IN" || true

      - name: 3) Zbuduj REPO_AUDIT.md z repo-snapshot.json
        run: |
          set -euo pipefail
          IN=".wtp/state/ro/public/latest/repo/repo-snapshot.json"
          OUT_DIR="_ci_logs/${RUN_ID}/repo_audit"
          OUT_FILE="${OUT_DIR}/REPO_AUDIT.md"
          mkdir -p "${OUT_DIR}"

          python - << 'PY'
          import json, os, re
          from pathlib import Path

          RUN_ID = os.environ["RUN_ID"]
          IN  = Path(".wtp/state/ro/public/latest/repo/repo-snapshot.json")
          OUT = Path(f"_ci_logs/{RUN_ID}/repo_audit/REPO_AUDIT.md")

          data  = json.load(IN.open(encoding="utf-8"))
          files = data.get("files", [])
          counts= data.get("counts", {})
          bycat = counts.get("by_category", {})

          def human(n):
              n = float(n or 0)
              units = ["B","KB","MB","GB","TB"]
              i=0
              while n>=1024 and i<len(units)-1:
                  n/=1024; i+=1
              return f"{n:.1f} {units[i]}"

          # grupy
          workflows = [f for f in files if f.get("category")=="workflow"]
          active_wf = [f for f in workflows if f["path"].startswith(".github/workflows/")]
          quar_wf   = [f for f in workflows if f["path"].startswith(".github/workflows._quarantine/")]
          mu        = [f for f in files if f["path"].startswith("wp-content/mu-plugins/")]
          plugins   = [f for f in files if f["path"].startswith("wp-content/plugins/")]
          themes    = [f for f in files if f["path"].startswith("wp-content/themes/")]
          wtp       = [f for f in files if f["path"].startswith(".wtp/")]

          # duże pliki
          large = sorted([f for f in files if (f.get("size") or 0) > 10*1024*1024],
                         key=lambda x: x.get("size") or 0, reverse=True)[:50]

          # top poddrzewa w .wtp
          from collections import defaultdict
          buckets = defaultdict(int)
          for f in wtp:
              p = f["path"].split("/")
              key = "/".join(p[:3]) if len(p)>=3 else "/".join(p[:2])
              buckets[key]+= (f.get("size") or 0)
          biggest = sorted(buckets.items(), key=lambda x:x[1], reverse=True)[:20]

          # rekomendacje wstępne
          rec = []
          rec.append("- Utrzymuj aktywne tylko 6 fundamentów w `.github/workflows/` (deploy/wpcli/snapshot + ai-upsert/apply-inbox-patch + gsc).")
          rec.append("- Pozostałe workflowy trzymaj w `.github/workflows._quarantine/` i przywracaj pojedynczo po stabilizacji.")
          rec.append("- Usuń lub zarchiwizuj duże pliki (>10MB), jeżeli nie muszą być w repo (limit GH 100MB).")
          rec.append("- W `.wtp/` zostaw `latest/` i kilka ostatnich runów; starsze katalogi przenieś do artefaktów.")
          rec.append("- MU-plugins: przejrzyj pod kątem martwych plików / dubli; trzymaj tylko realnie używane.")

          # render
          L=[]
          L.append("# REPO AUDIT")
          L.append(f"- Run ID: {data.get('run_id')}")
          L.append(f"- Run TS (UTC): {data.get('run_ts')}")
          L.append("")
          L.append("## Podsumowanie")
          L.append(f"- Plików łącznie: {counts.get('files')}")
          if bycat:
              L.append("- Kategorie:")
              for k in sorted(bycat.keys()):
                  v = bycat[k]
                  L.append(f"  - **{k}**: {v['count']} plików, {human(v['size'])}")
          L.append("")
          L.append(f"- Workflows: {len(workflows)} (aktywne: {len(active_wf)}, kwarantanna: {len(quar_wf)})")
          L.append(f"- MU-plugins: {len(mu)} • Plugins: {len(plugins)} • Themes: {len(themes)} • .wtp plików: {len(wtp)}")
          L.append("")

          L.append("## Workflows – aktywne")
          if active_wf:
              L.append("| Plik | Rozmiar | Linijki |")
              L.append("|---|---:|---:|")
              for f in sorted(active_wf, key=lambda x:x["path"]):
                  L.append(f"| {f['path']} | {human(f.get('size') or 0)} | {f.get('lines') or ''} |")
          else:
              L.append("_brak_")
          L.append("")

          L.append("## Workflows – kwarantanna")
          if quar_wf:
              L.append("| Plik | Rozmiar | Linijki |")
              L.append("|---|---:|---:|")
              for f in sorted(quar_wf, key=lambda x:x["path"]):
                  L.append(f"| {f['path']} | {human(f.get('size') or 0)} | {f.get('lines') or ''} |")
          else:
              L.append("_brak_")
          L.append("")

          L.append("## Największe pliki (>10MB)")
          if large:
              L.append("| Plik | Rozmiar | Kategoria |")
              L.append("|---|---:|---|")
              for f in large:
                  L.append(f"| {f['path']} | {human(f.get('size') or 0)} | {f.get('category')} |")
          else:
              L.append("_brak_")
          L.append("")

          L.append("## .wtp – największe poddrzewa")
          if biggest:
              L.append("| Poddrzewo | Rozmiar |")
              L.append("|---|---:|")
              for k, sz in biggest:
                  L.append(f"| {k} | {human(sz)} |")
          else:
              L.append("_brak_")
          L.append("")

          L.append("## Rekomendacje")
          for r in rec:
              L.append(f"- {r}")

          OUT.write_text("\n".join(L) + "\n", encoding="utf-8")
          print(f"[INFO] Wygenerowano {OUT}")
          PY

      - name: 4) Opublikuj REPO_AUDIT.md do latest/repo/
        run: |
          set -euo pipefail
          SRC="_ci_logs/${RUN_ID}/repo_audit/REPO_AUDIT.md"
          test -f "$SRC" || { echo "::error::Nie wygenerowano REPO_AUDIT.md"; exit 1; }
          RO_RUN=".wtp/state/ro/public/${RUN_ID}/repo"
          RO_LATEST=".wtp/state/ro/public/latest/repo"
          mkdir -p "${RO_RUN}" "${RO_LATEST}"
          cp -f "$SRC" "${RO_RUN}/REPO_AUDIT.md"
          cp -f "$SRC" "${RO_LATEST}/REPO_AUDIT.md"

          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add "${RO_RUN}/REPO_AUDIT.md" "${RO_LATEST}/REPO_AUDIT.md"
          if git diff --staged --quiet; then
            echo "::notice::Nothing to commit."
          else
            git commit -m "Publish REPO_AUDIT.md ${RUN_ID}"
            git push
          fi

      - name: 5) Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-audit-${{ github.run_id }}
          path: _ci_logs/${{ github.run_id }}/repo_audit/REPO_AUDIT.md
          retention-days: 14
