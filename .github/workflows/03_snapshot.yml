name: 03_snapshot (WordPress → SSOT, pełny stan)

on:
  workflow_run:
    workflows: ["02_wpcli (install/update/activate from SSOT, secure SSH)"]
    types: [completed]
  workflow_dispatch:
    inputs:
      commit_snapshot:
        description: "Commit snapshot.json do repo (.wtp/snapshots/)"
        type: boolean
        default: false

permissions:
  contents: write

concurrency:
  group: snapshot
  cancel-in-progress: true

jobs:
  snapshot:
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'workflow_run' &&
       github.event.workflow_run.conclusion == 'success')
    runs-on: ubuntu-latest
    timeout-minutes: 20
    env:
      WTP_CI: "1"
      HOST:   ${{ secrets.DEPLOY_HOST }}
      PORT:   ${{ secrets.DEPLOY_PORT }}
      USER:   ${{ secrets.DEPLOY_USER }}
      PASS:   ${{ secrets.DEPLOY_PASS }}
      TARGET: ${{ secrets.DEPLOY_TARGET }}

    steps:
      - name: 1) Checkout repo
        uses: actions/checkout@v4

      - name: 2) Setup tools + known_hosts (STRICT)
        shell: bash
        run: |
          set -euo pipefail
          for v in HOST PORT USER PASS TARGET; do
            [ -n "${!v:-}" ] || { echo "::error::Missing $v"; exit 1; }
          done
          sudo apt-get update -y
          sudo apt-get install -y curl sshpass jq
          mkdir -p ~/.ssh && chmod 700 ~/.ssh
          ssh-keyscan -p "${PORT}" "${HOST}" >> ~/.ssh/known_hosts
          chmod 644 ~/.ssh/known_hosts
          echo "::add-mask::$HOST"
          echo "::add-mask::$USER"

      - name: 3) Prepare local dirs
        shell: bash
        run: mkdir -p "_ci_logs/${{ github.run_id }}/snapshot"

      - name: 4) Create & upload snapshot script (heredoc)
        shell: bash
        run: |
          set -euo pipefail
          cat > /tmp/wtp_snapshot.sh <<'SNAPEOF'
          #!/usr/bin/env bash
          set -euo pipefail

          : "${TARGET:?TARGET is required}"
          : "${RUN_ID:?RUN_ID is required}"

          LOGDIR="${TARGET}/.wtp/state/ci_logs/snapshot"
          mkdir -p "${LOGDIR}"

          ERR_FILE="${LOGDIR}/errors.txt"; : > "${ERR_FILE}"
          note_err(){ echo "$1" | tee -a "${ERR_FILE}" 1>&2 || true; }
          run_wp(){ php ./wp "$@" --path="${TARGET}"; }

          # ---------- A) Site/Core ----------
          SITE_URL="$(run_wp option get siteurl 2>/dev/null || true)"
          SITE_HOME="$(run_wp option get home 2>/dev/null || true)"
          WP_VER="$(run_wp core version 2>/dev/null || true)"
          TABLE_PREFIX="$(grep -E "^\s*\\\$table_prefix\s*=" "${TARGET}/wp-config.php" 2>/dev/null | sed -E "s/.*['\"]([^'\"]+)['\"].*/\1/" | head -n1 || echo "wp_")"
          WPLANG="$(run_wp option get WPLANG 2>/dev/null || true)"
          TZ_STR="$(run_wp option get timezone_string 2>/dev/null || run_wp option get gmt_offset 2>/dev/null || true)"
          PHP_VERSION="$(php -r 'echo PHP_VERSION;' 2>/dev/null || true)"
          php -v > "${LOGDIR}/php_info.txt" 2>&1 || note_err "php -v failed."

          # Zapisz site_info.json bez jq – przez printf (PHP i tak scali)
          {
            printf '%s\n' '{'
            printf '  "url": "%s",\n' "${SITE_URL}"
            printf '  "home": "%s",\n' "${SITE_HOME}"
            printf '  "wp_version": "%s",\n' "${WP_VER}"
            printf '  "table_prefix": "%s",\n' "${TABLE_PREFIX}"
            printf '  "language": "%s",\n' "${WPLANG}"
            printf '  "timezone": "%s",\n' "${TZ_STR}"
            printf '  "php_version": "%s"\n' "${PHP_VERSION}"
            printf '%s\n' '}'
          } > "${LOGDIR}/site_info.json" || note_err "site_info.json write failed."

          # ---------- B) Themes ----------
          run_wp theme list --status=active --format=json > "${LOGDIR}/theme_active.json" 2>>"${ERR_FILE}" || note_err "wp theme list --status=active failed."
          run_wp theme list --format=json > "${LOGDIR}/themes.json" 2>>"${ERR_FILE}" || note_err "wp theme list --format=json failed."

          # ---------- C) Plugins ----------
          run_wp plugin list --format=json > "${LOGDIR}/plugins.json" 2>>"${ERR_FILE}" || note_err "wp plugin list --format=json failed."
          run_wp plugin list --format=csv  > "${LOGDIR}/plugins.csv"  2>>"${ERR_FILE}" || note_err "wp plugin list --format=csv failed."

          # ---------- C2) Per-plugin trees + SHA1 (nie wymaga jq) ----------
          PLUG_DIR="${TARGET}/wp-content/plugins"
          if [[ -d "${PLUG_DIR}" ]]; then
            # lista slugów z wp-cli, fallback: katalogi
            if [[ -s "${LOGDIR}/plugins.json" ]]; then
              # wyciągnij nazwę sluga prostym grepem/sed gdy brak jq
              sed -n 's/.*"name"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/p' "${LOGDIR}/plugins.json" | sort -u > "${LOGDIR}/_slugs.txt" || true
            else
              find "${PLUG_DIR}" -mindepth 1 -maxdepth 1 -type d -printf '%f\n' | sort > "${LOGDIR}/_slugs.txt" || true
            fi
            while IFS= read -r slug; do
              [[ -n "$slug" && -d "${PLUG_DIR}/${slug}" ]] || continue
              OUTDIR="${LOGDIR}/plugins/${slug}"; mkdir -p "${OUTDIR}"
              find "${PLUG_DIR}/${slug}" -type f -print0 | sort -z | tr '\0' '\n' > "${OUTDIR}/tree.txt" 2>>"${ERR_FILE}" || true
              { find "${PLUG_DIR}/${slug}" -type f -print0 | sort -z | xargs -0 sha1sum; } > "${OUTDIR}/hashes.sha1" 2>>"${ERR_FILE}" || true
            done < "${LOGDIR}/_slugs.txt"
          fi

          # ---------- D) MU-plugins ----------
          MU_DIR="${TARGET}/wp-content/mu-plugins"
          mkdir -p "${LOGDIR}/mu-plugins"
          if [[ -d "${MU_DIR}" ]]; then
            ls -la "${MU_DIR}" > "${LOGDIR}/mu-plugins/_ls.txt" 2>>"${ERR_FILE}" || note_err "ls mu-plugins failed."
            find "${MU_DIR}" -type f -print0 | sort -z | xargs -0 sha1sum > "${LOGDIR}/mu-plugins/_hashes.txt" 2>>"${ERR_FILE}" || true
            find "${MU_DIR}" -maxdepth 1 -type f -name "*.php" -print0 | \
              while IFS= read -r -d '' f; do
                head -n 50 "$f" | grep -E "^\s*\*\s*Plugin Name:" -m1 > "${LOGDIR}/mu-plugins/$(basename "$f").header.txt" 2>>"${ERR_FILE}" || true
              done
          else
            echo "mu-plugins directory not found." > "${LOGDIR}/mu-plugins/_ls.txt"
            : > "${LOGDIR}/mu-plugins/_hashes.txt"
          fi
          run_wp plugin list --status=must-use --format=json > "${LOGDIR}/mu_plugins.json" 2>>"${ERR_FILE}" || note_err "wp plugin list --status=must-use failed."

          # ---------- E) Users ----------
          run_wp user list --role=administrator --field=user_login --format=json > "${LOGDIR}/admins.json" 2>>"${ERR_FILE}" || note_err "wp user list --role=administrator failed."

          # ---------- F) WTP / SSOT ----------
          SSOT_PATH="${TARGET}/.wtp/ssot.yml"; SSOT_SHA1=""; SSOT_B64=""
          if [[ -f "${SSOT_PATH}" ]]; then
            cp "${SSOT_PATH}" "${LOGDIR}/ssot.yml" 2>>"${ERR_FILE}" || note_err "Copy ssot.yml failed."
            SSOT_SHA1="$(sha1sum "${SSOT_PATH}" | awk '{print $1}')" || true
            echo "${SSOT_SHA1}" > "${LOGDIR}/ssot.sha1" || true
            SSOT_B64="$(base64 -w0 "${SSOT_PATH}" 2>/dev/null || base64 "${SSOT_PATH}" | tr -d '\n')" || true
          else
            note_err "SSOT file .wtp/ssot.yml not found."
          fi

          # ---------- G) Server ----------
          SERVER_USER="$(whoami 2>/dev/null || true)"
          SERVER_UNAME="$(uname -a 2>/dev/null || true)"
          SERVER_DT="$(date -Is 2>/dev/null || true)"
          SERVER_CWD="$(cd "${TARGET}" && pwd 2>/dev/null || true)"
          {
            echo "user: ${SERVER_USER}"
            echo "uname: ${SERVER_UNAME}"
            echo "datetime: ${SERVER_DT}"
            echo "cwd: ${SERVER_CWD}"
          } > "${LOGDIR}/server_info.txt" 2>>"${ERR_FILE}" || note_err "server_info.txt failed."

          # ---------- H) Summary (active list) ----------
          run_wp plugin list --status=active --field=name --format=json > "${LOGDIR}/plugins_active.json" 2>>"${ERR_FILE}" || note_err "wp plugin list --status=active --field=name failed."
          if [[ -s "${LOGDIR}/plugins_active.json" ]]; then
            # dodatkowo txt (po jednym slugu)
            sed -n 's/[^"[]*"\([^"]\+\)".*/\1/p' "${LOGDIR}/plugins_active.json" > "${LOGDIR}/plugins_active.txt" 2>>"${ERR_FILE}" || true
          else
            : > "${LOGDIR}/plugins_active.txt"
          fi

          # ---------- I) Build snapshot.json w PHP (bez jq) ----------
          cat > /tmp/wtp_build_snapshot.php <<'PHPBUILDER'
          <?php
          error_reporting(E_ALL);
          $logdir = getenv('LOGDIR');
          $runId  = getenv('RUN_ID');
          $ts     = date('c');

          function jread($path, $def) {
            if (!file_exists($path) || !is_readable($path)) return $def;
            $txt = file_get_contents($path);
            $j = json_decode($txt, true);
            return is_array($j) || is_object($j) ? $j : $def;
          }
          function fread_or($path, $def='') {
            return (file_exists($path) && is_readable($path)) ? file_get_contents($path) : $def;
          }

          $site   = jread("$logdir/site_info.json", new stdClass());
          $themes = jread("$logdir/themes.json", []);
          $tact   = jread("$logdir/theme_active.json", []);
          $themeActive = (is_array($tact) && count($tact)>0) ? $tact[0] : null;

          $pluginsStd = jread("$logdir/plugins.json", []);
          $pluginsMU  = jread("$logdir/mu_plugins.json", []);
          $admins     = jread("$logdir/admins.json", []);

          $pluginsActive = jread("$logdir/plugins_active.json", []);

          // trees summary (z plików tree.txt i hashes.sha1)
          $trees = [];
          $pluginsDir = "$logdir/plugins";
          if (is_dir($pluginsDir)) {
            foreach (scandir($pluginsDir) as $slug) {
              if ($slug === '.' || $slug === '..') continue;
              $pdir = "$pluginsDir/$slug";
              if (!is_dir($pdir)) continue;
              $treeFile  = "$pdir/tree.txt";
              $hashes    = "$pdir/hashes.sha1";
              $files = (file_exists($treeFile)) ? max(0, count(file($treeFile, FILE_IGNORE_NEW_LINES))) : 0;
              $sha = '';
              if (file_exists($hashes)) {
                $all = preg_replace('/\s+.*/', '', file_get_contents($hashes));
                $all = preg_replace('/\s+/', '', $all);
                $sha = substr(sha1($all), 0, 40);
              }
              $trees[$slug] = ['files'=>$files, 'sha1'=>$sha];
            }
          }

          // counts
          $counts = [
            'themes_total'   => is_array($themes) ? count($themes) : 0,
            'plugins_total'  => is_array($pluginsStd) ? count($pluginsStd) : 0,
            'plugins_active' => is_array($pluginsActive) ? count($pluginsActive) : 0,
            'plugins_mu'     => is_array($pluginsMU) ? count($pluginsMU) : 0,
            'admins'         => is_array($admins) ? count($admins) : 0
          ];

          // errors
          $errors = [];
          $errPath = "$logdir/errors.txt";
          if (file_exists($errPath)) {
            $lines = array_filter(array_map('trim', file($errPath)));
            $errors = array_values($lines);
          }

          // server info (tekst -> array)
          $srv = ['user'=>'','uname'=>'','datetime'=>'','cwd'=>''];
          $si = fread_or("$logdir/server_info.txt");
          if ($si) {
            foreach (explode("\n", $si) as $ln) {
              if (preg_match('/^([a-z]+):\s*(.*)$/i', trim($ln), $m)) {
                $srv[$m[1]] = $m[2];
              }
            }
          }

          // ssot
          $ssot_path = '.wtp/ssot.yml';
          $ssot_sha1 = trim(fread_or("$logdir/ssot.sha1"));
          $ssot_b64  = trim(fread_or("$logdir/ssot.yml")) ? base64_encode(fread_or("$logdir/ssot.yml")) : '';

          $out = [
            'run_id'    => intval($runId),
            'timestamp' => $ts,
            'site'      => $site,
            'server'    => $srv,
            'theme'     => ['active'=>$themeActive, 'all'=>$themes],
            'plugins'   => ['standard'=>$pluginsStd, 'must_use'=>$pluginsMU, 'trees'=>$trees],
            'admins'    => $admins,
            'summary'   => ['plugins_active'=>$pluginsActive, 'counts'=>$counts, 'errors'=>$errors],
            'wtp'       => ['ssot_path'=>$ssot_path, 'ssot_sha1'=>$ssot_sha1, 'ssot_b64'=>$ssot_b64]
          ];

          file_put_contents("$logdir/snapshot.json", json_encode($out, JSON_UNESCAPED_SLASHES|JSON_UNESCAPED_UNICODE));
          PHPBUILDER

          LOGDIR="${LOGDIR}" RUN_ID="${RUN_ID}" php /tmp/wtp_build_snapshot.php 2>>"${ERR_FILE}" || note_err "snapshot.json build failed."
          rm -f /tmp/wtp_build_snapshot.php || true
          SNAPEOF

          chmod +x /tmp/wtp_snapshot.sh
          sshpass -p "${PASS}" scp -P "${PORT}" -o StrictHostKeyChecking=yes /tmp/wtp_snapshot.sh ${USER}@${HOST}:/tmp/wtp_snapshot.sh

      - name: 5) Run remote snapshot script
        shell: bash
        run: |
          set -euo pipefail
          sshpass -p "${PASS}" ssh -p "${PORT}" -o StrictHostKeyChecking=yes \
            "${USER}@${HOST}" "RUN_ID='${{ github.run_id }}' TARGET='${TARGET}' bash /tmp/wtp_snapshot.sh && rm -f /tmp/wtp_snapshot.sh"

      - name: 6) Pull logs back
        shell: bash
        run: |
          set -euo pipefail
          sshpass -p "${PASS}" scp -P "${PORT}" -o StrictHostKeyChecking=yes -r \
            "${USER}@${HOST}:${TARGET}/.wtp/state/ci_logs/snapshot" "_ci_logs/${{ github.run_id }}/"

      - name: 7) Upload artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: snapshot-logs-${{ github.run_id }}
          path: _ci_logs/${{ github.run_id }}/snapshot/**

      - name: 8) Validate snapshot.json
        shell: bash
        run: |
          set -euo pipefail
          SNAP="_ci_logs/${{ github.run_id }}/snapshot/snapshot.json"
          if [[ -s "$SNAP" ]]; then
            echo "::notice::Snapshot JSON created ($(wc -c < "$SNAP") bytes)"
            jq empty "$SNAP" || echo "::warning::JSON may be malformed"
          else
            echo "::error::No snapshot.json generated"; exit 1
          fi

      - name: 9) Report summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          ERR="_ci_logs/${{ github.run_id }}/snapshot/errors.txt"
          if [[ -s "$ERR" ]]; then
            echo "::group::Snapshot errors"
            cat "$ERR" || true
            echo "::endgroup::"
            while IFS= read -r line; do
              [[ -n "$line" ]] && echo "::warning::$line"
            done < "$ERR"
          fi
          echo "::notice::03_snapshot completed for run ${{ github.run_id }}."

  commit_snapshot:
    needs: snapshot
    if: ${{ inputs.commit_snapshot == true }}
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Download snapshot artifact
        uses: actions/download-artifact@v4
        with:
          name: snapshot-logs-${{ github.run_id }}
          path: _ci_logs/${{ github.run_id }}/snapshot/

      - name: Commit snapshot.json
        shell: bash
        run: |
          set -euo pipefail
          SRC="_ci_logs/${{ github.run_id }}/snapshot/snapshot.json"
          DEST_DIR=".wtp/snapshots"
          DEST_FILE="${DEST_DIR}/snapshot-${{ github.run_id }}.json"
          [[ -s "$SRC" ]] || { echo "::error::snapshot.json missing"; exit 1; }
          mkdir -p "$DEST_DIR"
          cp "$SRC" "$DEST_FILE"
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add "$DEST_FILE"
          if git diff --staged --quiet; then
            echo "::notice::No changes to commit."
          else
            git commit -m "Add snapshot JSON for run ${{ github.run_id }}"
            git push
          fi
